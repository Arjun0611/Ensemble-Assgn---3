{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc378ee-b152-4cbd-acc1-c025274eba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.\n",
    "\n",
    "# Random Forest Regressor:\n",
    "    # Ensemble Method: It is an ensemble learning algorithm used for regression tasks.\n",
    "    # Multile Decision Trees: Constructs multiple decision trees during training.\n",
    "    # Bagging: Trains each tree on a random subset of the training data with replacement.\n",
    "    # Averaging Predictions: Predcitions are averaged for improved accuracy and robustness.\n",
    "    # Feature Randomization: Randomly selects a subset of features for each tree, reducing overfitting.\n",
    "    # Versatility: Effective for handling non-linear relationships and capturing complex paaterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462a62f6-a732-4098-afc1-b1323d2f6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.\n",
    "\n",
    "# Reduction of overfitting in Random Forest Regressor:\n",
    "    # Ensemble of Trees: Constructs multiple decision trees.\n",
    "    # Random subset sampling: Trains each tree on a random subset of the data.\n",
    "    # Feature Randomization: Randomly selects a subset of features for each tree.\n",
    "    # Averaging Predcitions: Combines predictions through averaging.\n",
    "    # Collective Decision: Reduces the risk of overfitting by mitigating the impact of individual noisy trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bbe619-d896-4d0c-9faa-dde981581f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.\n",
    "\n",
    "# Aggregration in Random Forest Regressor:\n",
    "    # Averaging: For regression, predcitions from multiple decision trees are averaged.\n",
    "    # Mean Predcition: The final prediction is the mean of individual tree predictions.\n",
    "    # Reduces Variance: Averaging helps to smooth out individual tree idiosyncrasies, reducing overfitting and providing a more stable prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d577381-0d2b-4672-942e-0a438c7d017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4.\n",
    "\n",
    "# Hyperparameters of Random Forest Regressor:\n",
    "    # n_estimators: Number of decision trees in the forest.\n",
    "    # max_depth: Maximum depth of individual trees to control overfitting.\n",
    "    # min_samples_split: Minimum number of samples required to split a node.\n",
    "    # min_samples_leaf: Minimum number of samples required in a leaf node.\n",
    "    # max_features: Maximum number of features considered for splitting a node.\n",
    "    # bootstrap: Whether to use bootstrap samples for training each tree.\n",
    "    # random_state: Seed for random number generation, ensuring reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e7308d-a2d0-4dde-a6d8-0067d150f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5.\n",
    "\n",
    "# Random Forest Regressor vs Decision Tree Regressor:\n",
    "    # Ensemble vs Single Tree:\n",
    "        # Random Forest is an ensemble of multiple decision trees.\n",
    "        # Decision Tree Regressor is a single decision tree.\n",
    "    # Bootstrap Aggregrating:\n",
    "        # Random Forest uses bagging to train each tree on a random subset of the data.\n",
    "        # Decision Tree Regressor uses the entire dataset to train a single tree.\n",
    "    # Variance and Overfitting:\n",
    "        # Random Forest aims to reduce overfitting and variance by aggregating predictions.\n",
    "        # Decision Tree Regressor may be prone to overfitting, especially on noisy datasets.\n",
    "    # Predictions: \n",
    "        # Random Forest predicts by averaging the predictions of individual trees.\n",
    "        # Decision Tree Regressor predicts based on the structure of the single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8eea9e9-89e5-4a30-93bf-a9de901154e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6.\n",
    "\n",
    "# Advantages:\n",
    "    # High Accuracy\n",
    "    # Reduction of overfitting\n",
    "    # Versatility: Effective for both classification and regression tasks.\n",
    "    # Handles missing values\n",
    "# Disadvantages:\n",
    "    # Complexity: May get complex with a large number of trees.\n",
    "    # Computational Cost\n",
    "    # Less interpretability\n",
    "    # May not perform well on datasets with primarily linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8a3668-3a83-404a-b34e-1b52410d8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7.\n",
    "\n",
    "# Continuous Predictions: Outputs a continuous prediction for regression tasks.\n",
    "# Average Prediction: The final prediction is often the avergae of predictions from individual decision trees.\n",
    "# Real-Valued Output: The output represents the predicted numerical value for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7c2e1d-3a59-4499-86bf-a8777ed6589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8.\n",
    "\n",
    "# Yes, Random Forest Regressor can be adapted for classification tasks.\n",
    "# Thresholding Output: Convert real-valued predictions into class labels based on a threshold.\n",
    "# Majority Voting: Utilize majority voting among decision trees for class assignment.\n",
    "# Commonly Used: Random Forest Classifier is more commonly employed for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f237741-b8af-4d83-b357-db37bfbb25ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
